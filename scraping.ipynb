{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Wikipedia 2018/2016 top 100 Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is scraping the '100 most visited cities in 2016/2018 according to Euromonitor' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_url = 'https://en.wikipedia.org/wiki/List_of_cities_by_international_visitors'\n",
    "r = requests.get(wiki_url)\n",
    "text = r.text\n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "tables = pd.read_html(wiki_url)\n",
    "top_cities = tables[2]\n",
    "\n",
    "top_cities = top_cities.dropna(subset= ['Rank (Euromonitor)'])\n",
    "final_top = top_cities[['Rank (Euromonitor)', 'City', 'Country / Territory']]\n",
    "\n",
    "final_top.to_csv('top_cities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the BudgetYourTrip.com links to the top_cities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank (Euromonitor)</th>\n",
       "      <th>City</th>\n",
       "      <th>Country / Territory</th>\n",
       "      <th>Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>https://www.budgetyourtrip.com/hong-kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>https://www.budgetyourtrip.com/thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https://www.budgetyourtrip.com/united-kingdom/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Macau</td>\n",
       "      <td>Macau</td>\n",
       "      <td>https://www.budgetyourtrip.com/budgetreportadv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>https://www.budgetyourtrip.com/singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.0</td>\n",
       "      <td>Jeju</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>https://www.budgetyourtrip.com/south-korea/che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.0</td>\n",
       "      <td>Porto</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>https://www.budgetyourtrip.com/portugal/porto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.0</td>\n",
       "      <td>Rhodes</td>\n",
       "      <td>Greece</td>\n",
       "      <td>https://www.budgetyourtrip.com/greece/rhodes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.0</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>https://www.budgetyourtrip.com/brazil/rio-de-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Krabi</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>https://www.budgetyourtrip.com/thailand/krabi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank (Euromonitor)            City Country / Territory  \\\n",
       "0                  1.0       Hong Kong           Hong Kong   \n",
       "1                  2.0         Bangkok            Thailand   \n",
       "2                  3.0          London      United Kingdom   \n",
       "3                  4.0           Macau               Macau   \n",
       "4                  5.0       Singapore           Singapore   \n",
       "..                 ...             ...                 ...   \n",
       "95                96.0            Jeju         South Korea   \n",
       "96                97.0           Porto            Portugal   \n",
       "97                98.0          Rhodes              Greece   \n",
       "98                99.0  Rio de Janeiro              Brazil   \n",
       "99               100.0           Krabi            Thailand   \n",
       "\n",
       "                                                Links  \n",
       "0            https://www.budgetyourtrip.com/hong-kong  \n",
       "1             https://www.budgetyourtrip.com/thailand  \n",
       "2   https://www.budgetyourtrip.com/united-kingdom/...  \n",
       "3   https://www.budgetyourtrip.com/budgetreportadv...  \n",
       "4            https://www.budgetyourtrip.com/singapore  \n",
       "..                                                ...  \n",
       "95  https://www.budgetyourtrip.com/south-korea/che...  \n",
       "96      https://www.budgetyourtrip.com/portugal/porto  \n",
       "97       https://www.budgetyourtrip.com/greece/rhodes  \n",
       "98  https://www.budgetyourtrip.com/brazil/rio-de-j...  \n",
       "99      https://www.budgetyourtrip.com/thailand/krabi  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = \"top_cities.csv\" \n",
    "city_links = \"city_links.txt\"\n",
    "output_file = \"cities.csv\"\n",
    "\n",
    "\n",
    "cities = pd.read_csv(cities)\n",
    "\n",
    "\n",
    "with open(city_links, \"r\", encoding=\"utf-8\") as f:\n",
    "    city_urls = [line.strip() for line in f.readlines()[1:]]  \n",
    "\n",
    "\n",
    "if len(cities) != len(city_urls):\n",
    "    raise ValueError(\"Error: The number of cities and URLs do not match!\")\n",
    "\n",
    "\n",
    "cities[\"Links\"] = city_urls\n",
    "\n",
    "\n",
    "cities.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "cities = cities.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "pd.DataFrame(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping stay duration costs from BudgetYourTrip.com (with written consent from BudgetYourTrip.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Terms of Use asks to not use web scrapers on their data, so I emailed them and asked if I could scrape their website for the pricing information. They gave me permission, however I will not be publicly displaying the scraped data from their website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cities.csv\")\n",
    "\n",
    "scraped_duration_data = []\n",
    "\n",
    "# clean_cost() cleans the cost data and converts it to a float\n",
    "\n",
    "def clean_cost(text):\n",
    "    try:\n",
    "        return float(text.replace(\",\", \"\").strip())  # Convert to float\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "# scraping the costs from a single URL\n",
    "def scrape_duration_costs(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        response.raise_for_status()  \n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        costs = soup.find_all(\"span\", class_=\"curvalue\")\n",
    "\n",
    "        if len(costs) >= 7:  \n",
    "            daily_cost = costs[0].text.strip()\n",
    "            one_week_person = costs[1].text.strip()\n",
    "            two_weeks_person = costs[2].text.strip()\n",
    "            one_month_person = costs[3].text.strip()\n",
    "            one_week_couple = costs[4].text.strip()\n",
    "            two_weeks_couple = costs[5].text.strip()\n",
    "            one_month_couple = costs[6].text.strip()\n",
    "        else:\n",
    "            return None  \n",
    "\n",
    "        return {\n",
    "            \"Links\": url,\n",
    "            \"Daily Cost\": clean_cost(costs[0].text),\n",
    "            \"1 Week (Individual)\": clean_cost(costs[1].text),\n",
    "            \"2 Weeks (Individual)\": clean_cost(costs[2].text),\n",
    "            \"1 Month (Individual)\": clean_cost(costs[3].text),\n",
    "            \"1 Week (Couple)\": clean_cost(costs[4].text),\n",
    "            \"2 Weeks (Couple)\": clean_cost(costs[5].text),\n",
    "            \"1 Month (Couple)\": clean_cost(costs[6].text),\n",
    "        }\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# scraping the costs from multiple URLs\n",
    "for index, row in df.iterrows():\n",
    "    url = row[\"Links\"]\n",
    "    cost_data = scrape_duration_costs(url)\n",
    "    \n",
    "    if cost_data:\n",
    "        scraped_duration_data.append(cost_data)\n",
    "\n",
    "    time.sleep(1)  \n",
    "\n",
    "# creating a DataFrame from the scraped data\n",
    "scraped_duration_df = pd.DataFrame(scraped_duration_data)\n",
    "\n",
    "# saving the scraped data to a CSV file\n",
    "scraped_duration_df.to_csv(\"scraped_duration_costs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the \"Mid-range\" column from the \"___ on a Budget\" Tables on BudgetYourTrip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Selenium WebDriver (headless mode) because the tables are in JavaScript\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run without opening a browser\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# Function to clean and convert cost values to float\n",
    "def clean_cost1(value):\n",
    "    \"\"\"\n",
    "    Cleans extracted cost values by:\n",
    "    - Removing $ signs\n",
    "    - Removing currency conversions in parentheses\n",
    "    - Handling ranges (taking the average)\n",
    "    - Converting valid numbers to floats\n",
    "    \"\"\"\n",
    "    if not value:\n",
    "        return None  # Return None if value is empty\n",
    "\n",
    "    # Remove dollar signs and extra whitespace\n",
    "    value = value.replace(\"$\", \"\").strip()\n",
    "\n",
    "    # Remove currency conversion values in parentheses\n",
    "    value = re.sub(r\"\\(.*?\\)\", \"\", value)\n",
    "\n",
    "    # Handle ranges (e.g., \"2-7\" → Convert to average (2+7)/2 = 4.5)\n",
    "    if \"-\" in value:\n",
    "        numbers = [float(n) for n in value.split(\"-\") if n.strip().replace(\".\", \"\").isdigit()]\n",
    "        if numbers:\n",
    "            return sum(numbers) / len(numbers)  # Return the average\n",
    "\n",
    "    # Convert to float if valid\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None  # Return None if conversion fails\n",
    "\n",
    "# Function to scrape the mid-range column from a table\n",
    "def scrape_mid_range(url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Wait for JavaScript to load\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        table = soup.find(\"table\")\n",
    "\n",
    "        if not table:\n",
    "            # the line below is for debugging purposes/ to see which URL doesn't have a table\n",
    "            print(f\"Skipping {url}: Table not found\")\n",
    "            return None\n",
    "\n",
    "        rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "        city_data = {\"URL\": url}\n",
    "\n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) >= 3:\n",
    "                category = cells[0].text.strip()  # First column: Category\n",
    "                mid_range_value = clean_cost1(cells[2].text.strip())  # Third column: Mid-Range\n",
    "                \n",
    "                city_data[category] = mid_range_value\n",
    "\n",
    "        return city_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to loop through all links in cities.csv\n",
    "def scrape_all_links(csv_file):\n",
    "    df_cities = pd.read_csv(csv_file)\n",
    "\n",
    "    scraped_data = []\n",
    "    \n",
    "    for index, row in df_cities.iterrows():\n",
    "        url = row[\"Links\"]\n",
    "        #print(f\"Scraping: {url}\")\n",
    "\n",
    "        city_costs = scrape_mid_range(url)\n",
    "        if city_costs:\n",
    "            scraped_data.append(city_costs)\n",
    "\n",
    "        time.sleep(1)  # Prevent rate-limiting\n",
    "\n",
    "    # Convert scraped data into a DataFrame\n",
    "    df_scraped = pd.DataFrame(scraped_data)\n",
    "\n",
    "    # renaming the \"URL\" column to \"Links\" \n",
    "    df_scraped = df_scraped.rename(columns={\"URL\": \"Links\"})\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    df_scraped.to_csv(\"mid_range_costs.csv\", index=False)\n",
    "\n",
    "    # Display the scraped data\n",
    "    df_scraped\n",
    "# Run the scraper for all the links\n",
    "scrape_all_links(\"cities.csv\")\n",
    "\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Links</th>\n",
       "      <th>Accommodation1</th>\n",
       "      <th>Local Transportation1</th>\n",
       "      <th>Food2</th>\n",
       "      <th>Entertainment1</th>\n",
       "      <th>Alcohol2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.budgetyourtrip.com/hong-kong</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>54.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.budgetyourtrip.com/thailand</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.budgetyourtrip.com/united-kingdom/...</td>\n",
       "      <td>158.0</td>\n",
       "      <td>33.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.budgetyourtrip.com/budgetreportadv...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.budgetyourtrip.com/singapore</td>\n",
       "      <td>99.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Links  Accommodation1  \\\n",
       "0           https://www.budgetyourtrip.com/hong-kong            77.0   \n",
       "1            https://www.budgetyourtrip.com/thailand            38.0   \n",
       "2  https://www.budgetyourtrip.com/united-kingdom/...           158.0   \n",
       "3  https://www.budgetyourtrip.com/budgetreportadv...           114.0   \n",
       "4           https://www.budgetyourtrip.com/singapore            99.0   \n",
       "\n",
       "   Local Transportation1  Food2  Entertainment1  Alcohol2  \n",
       "0                   8.78   54.0            95.0      20.5  \n",
       "1                  13.00   30.0            20.0       9.5  \n",
       "2                  33.00   75.0            41.0      19.5  \n",
       "3                   1.00   37.0            11.0       NaN  \n",
       "4                  10.00   46.0            33.0      27.5  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixing the mid_range_costs.csv file column names\n",
    "mid_range_costs = pd.read_csv(\"mid_range_costs.csv\", header=None, skiprows=1)\n",
    "\n",
    "# manually setting correct column names\n",
    "mid_range_costs.columns = [\"Links\", \"Accommodation1\", \"Local Transportation1\", \"Food2\", \"Entertainment1\", \"Alcohol2\"]\n",
    "\n",
    "mid_range_costs.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the .csv files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the files made in the previous steps\n",
    "cities_df = pd.read_csv(\"cities.csv\")\n",
    "costs_df = pd.read_csv(\"scraped_duration_costs.csv\")\n",
    "\n",
    "# merging the cities & scraped_duration_costs dataframes\n",
    "cities_costs = pd.merge(cities_df, costs_df, on=\"Links\", how=\"left\")\n",
    "cities_costs_cleaned = cities_costs.drop_duplicates(subset=[\"City\", \"Country / Territory\"], keep=\"first\")\n",
    "\n",
    "# merging the cities_costs_cleaned & mid_range_costs dataframes\n",
    "final_df = pd.merge(cities_costs_cleaned, mid_range_costs, on=\"Links\", how=\"left\")\n",
    "final_df = final_df.drop_duplicates(subset=[\"City\", \"Country / Territory\"], keep=\"first\")\n",
    "\n",
    "# dropping the \"Unnamed: 0\" column\n",
    "final_df = final_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# saving the final dataframe to a CSV file \n",
    "final_df.to_csv(\"final_trip_costs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env386",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
